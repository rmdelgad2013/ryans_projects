{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Probability of Default in Fannie Mae Loans\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warning for odd numpy/statsmodels VisibleDeprecationWarning in KDE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('%s/train.csv' % settings.PROCESSED_DIR, header=0)\n",
    "train_df = train_df[~train_df['foreclosure_status'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create categorical groupby DataFrame for categorical bar plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_vars = ['channel','loan_purpose','first_time_homebuyer', 'borrower_count', 'occupancy_status']\n",
    "groupby_frames = {}\n",
    "\n",
    "for v in cat_vars:\n",
    "    # Calculate the total count of each foreclosure_status & categorical variable combination\n",
    "    groupby_frames[v] = train_df.groupby(['foreclosure_status',v])[v].count()\n",
    "\n",
    "    # Calculate percentage share of foreclosure_status-level percentage of each facet of the categorical variable\n",
    "    groupby_frames[v] =  groupby_frames[v].groupby(level=0).apply(lambda x: x/float(x.sum()))\n",
    "    groupby_frames[v] = pd.DataFrame(groupby_frames[v])\n",
    "    groupby_frames[v].columns = ['share']\n",
    "\n",
    "    # Flatten groupby frame to prepare for bar plot\n",
    "    groupby_frames[v] = groupby_frames[v].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce KDE pair plots for the continuous variables, and bar plots for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kde_pair_subplot(ax, var_name, title):\n",
    "    for tf in [True, False]:\n",
    "        data = train_df.ix[train_df['foreclosure_status'] == tf, var_name]\n",
    "        data = data[~data.isnull()]\n",
    "        sns.kdeplot(data, legend=False, ax=ax)\n",
    "    sns.plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    ax.set_title(title)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = ['Foreclosure', 'No Foreclosure']\n",
    "    if (ax == ax1) or (ax == ax4) or (ax == ax5):\n",
    "        ax.legend(handles, labels, loc='upper left')\n",
    "    else:\n",
    "        ax.legend(handles, labels)\n",
    "        \n",
    "def share_bar_subplot(ax, var_name, title):\n",
    "    data = groupby_frames[var_name]\n",
    "    sns.barplot(x=var_name, y='share', hue='foreclosure_status', data=data, ax=ax)\n",
    "    sns.plt.setp(ax.get_xticklabels())\n",
    "\n",
    "    # Set title and ylabel\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Share')\n",
    "\n",
    "    # Set legends for each plot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles = handles[:2]\n",
    "    labels = ['Foreclosure','No Foreclosure']\n",
    "    if ax == ax6: # the legend in the first bar plot will overlap with the bars if it's left in the upper right\n",
    "        ax.legend(handles, labels, loc='upper left')\n",
    "    else:\n",
    "        ax.legend(handles, labels)\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = sns.plt.subplots(5,2)\n",
    "kde_axs = [ax1, ax2, ax3, ax4, ax5]\n",
    "kde_vars = ['borrower_credit_score', 'interest_rate', 'balance', 'cltv', 'dti']\n",
    "kde_titles = ['Borrower Credit Score', 'Interest Rate', 'Balance', 'Combined Loan-to-Value', 'Debt-to-Income']\n",
    "\n",
    "cat_axs = [ax6, ax7, ax8, ax9, ax10]\n",
    "cat_vars = ['channel','loan_purpose','first_time_homebuyer', 'borrower_count', 'occupancy_status']\n",
    "cat_titles = ['Channel', 'Loan Purpose', 'First Time Homebuyer', 'Borrower Count', 'Occupancy Status']\n",
    "\n",
    "for ax,var,title in zip(kde_axs, kde_vars, kde_titles):\n",
    "    kde_pair_subplot(ax, var, title)\n",
    "\n",
    "for ax,var,title in zip(cat_axs, cat_vars, cat_titles):\n",
    "    share_bar_subplot(ax,var,title)\n",
    "    \n",
    "f.subplots_adjust(hspace=0.6, wspace=0.2)\n",
    "f.set_size_inches(12, 15)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an initial peek at what matters in determining the foreclosure rate. We'll use the Logit model from statsmodels to get z statistics & p values for each predictor coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002762\n",
      "         Iterations 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>foreclosure_status_True</td> <th>  No. Observations:  </th>  <td>4199190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>          <th>  Df Residuals:      </th>  <td>4199175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>  <td>    14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 11 Aug 2016</td>     <th>  Pseudo R-squ.:     </th>  <td>0.1047</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:37:29</td>         <th>  Log-Likelihood:    </th> <td> -11597.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>           <th>  LL-Null:           </th> <td> -12952.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                         <td> </td>            <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>    8.7723</td> <td>    0.867</td> <td>   10.114</td> <td> 0.000</td> <td>    7.072    10.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_div_cltv</th>         <td>    0.0134</td> <td>    0.015</td> <td>    0.879</td> <td> 0.380</td> <td>   -0.017     0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>borrower_credit_score</th>  <td>   -0.0108</td> <td>    0.001</td> <td>  -16.823</td> <td> 0.000</td> <td>   -0.012    -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cltv</th>                   <td>    0.0805</td> <td>    0.004</td> <td>   21.206</td> <td> 0.000</td> <td>    0.073     0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interest_rate</th>          <td>   -0.1962</td> <td>    0.058</td> <td>   -3.368</td> <td> 0.001</td> <td>   -0.310    -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dti</th>                    <td>    0.0310</td> <td>    0.003</td> <td>    8.933</td> <td> 0.000</td> <td>    0.024     0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance_log</th>            <td>   -1.3225</td> <td>    0.049</td> <td>  -26.719</td> <td> 0.000</td> <td>   -1.420    -1.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>first_time_homebuyer_Y</th> <td>   -0.5242</td> <td>    0.085</td> <td>   -6.164</td> <td> 0.000</td> <td>   -0.691    -0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_C</th>              <td>    0.0839</td> <td>    0.099</td> <td>    0.845</td> <td> 0.398</td> <td>   -0.111     0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>channel_R</th>              <td>    0.0062</td> <td>    0.097</td> <td>    0.064</td> <td> 0.949</td> <td>   -0.184     0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loan_purpose_C</th>         <td>    0.2905</td> <td>    0.076</td> <td>    3.802</td> <td> 0.000</td> <td>    0.141     0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loan_purpose_P</th>         <td>   -1.0580</td> <td>    0.075</td> <td>  -14.186</td> <td> 0.000</td> <td>   -1.204    -0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single_borrower_Y</th>      <td>    0.7966</td> <td>    0.063</td> <td>   12.568</td> <td> 0.000</td> <td>    0.672     0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupancy_status_I</th>     <td>   -0.4444</td> <td>    0.220</td> <td>   -2.021</td> <td> 0.043</td> <td>   -0.875    -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupancy_status_P</th>     <td>    0.3985</td> <td>    0.174</td> <td>    2.288</td> <td> 0.022</td> <td>    0.057     0.740</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              Logit Regression Results                             \n",
       "===================================================================================\n",
       "Dep. Variable:     foreclosure_status_True   No. Observations:              4199190\n",
       "Model:                               Logit   Df Residuals:                  4199175\n",
       "Method:                                MLE   Df Model:                           14\n",
       "Date:                     Thu, 11 Aug 2016   Pseudo R-squ.:                  0.1047\n",
       "Time:                             20:37:29   Log-Likelihood:                -11597.\n",
       "converged:                            True   LL-Null:                       -12952.\n",
       "                                             LLR p-value:                     0.000\n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                      8.7723      0.867     10.114      0.000         7.072    10.472\n",
       "score_div_cltv             0.0134      0.015      0.879      0.380        -0.017     0.043\n",
       "borrower_credit_score     -0.0108      0.001    -16.823      0.000        -0.012    -0.010\n",
       "cltv                       0.0805      0.004     21.206      0.000         0.073     0.088\n",
       "interest_rate             -0.1962      0.058     -3.368      0.001        -0.310    -0.082\n",
       "dti                        0.0310      0.003      8.933      0.000         0.024     0.038\n",
       "balance_log               -1.3225      0.049    -26.719      0.000        -1.420    -1.226\n",
       "first_time_homebuyer_Y    -0.5242      0.085     -6.164      0.000        -0.691    -0.357\n",
       "channel_C                  0.0839      0.099      0.845      0.398        -0.111     0.278\n",
       "channel_R                  0.0062      0.097      0.064      0.949        -0.184     0.196\n",
       "loan_purpose_C             0.2905      0.076      3.802      0.000         0.141     0.440\n",
       "loan_purpose_P            -1.0580      0.075    -14.186      0.000        -1.204    -0.912\n",
       "single_borrower_Y          0.7966      0.063     12.568      0.000         0.672     0.921\n",
       "occupancy_status_I        -0.4444      0.220     -2.021      0.043        -0.875    -0.013\n",
       "occupancy_status_P         0.3985      0.174      2.288      0.022         0.057     0.740\n",
       "==========================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.44 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify labels and features to use for classification models\n",
    "label = 'foreclosure_status_True'\n",
    "features = ['score_div_cltv','borrower_credit_score','cltv','interest_rate', 'dti', 'balance_log', 'first_time_homebuyer_Y',\n",
    "            'channel_C','channel_R', 'loan_purpose_C','loan_purpose_P', 'single_borrower_Y', 'occupancy_status_I',\n",
    "            'occupancy_status_P']\n",
    "\n",
    "# Fit the Logit model\n",
    "logit = sm.Logit(train_df[label], sm.add_constant(train_df[features]))\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the predictors are statistically significant, as expected. I was surprised the score_div_cltv predictor wasn't significant, since that one was suggested in the Fannie Mae data tutorials on http://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use scikit-learn's LogisticRegression model and cross_val_predict function to train & cross-validate a Logistic Regression model. Then we'll calcualte some binary classification performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score: 0.752699687321\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[3159565 1038182]\n",
      " [    279    1164]]\n",
      "Logistic Regression Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      1.00      0.86   3159844\n",
      "        1.0       0.81      0.00      0.00   1039346\n",
      "\n",
      "avg / total       0.77      0.75      0.65   4199190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "# Create a LogRet model, then cross validate the model on the training dataset using cross_val_predict\n",
    "logistic_model = LogisticRegression(class_weight='balanced')\n",
    "logistic_predictions = cross_val_predict(logistic_model, train_df[features], train_df[label], cv=4)\n",
    "\n",
    "# Evaluate logistic regression model with accuracy score, a confusion matrix, and a classification report\n",
    "print('Logistic Regression Accuracy Score: %s' %metrics.accuracy_score(train_df[label], logistic_predictions))\n",
    "\n",
    "print('Logistic Regression Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(train_df[label], logistic_predictions))\n",
    "\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(metrics.classification_report(logistic_predictions, train_df[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if a Random Forest Classifier gives us more accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score: 0.875484319595\n",
      "Random Forest Confusion Matrix:\n",
      "[[3675530  522217]\n",
      " [    648     795]]\n",
      "Random Forest Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      1.00      0.93   3676178\n",
      "        1.0       0.55      0.00      0.00    523012\n",
      "\n",
      "avg / total       0.84      0.88      0.82   4199190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_model = RandomForestClassifier(max_depth=10, n_estimators=40, class_weight='balanced')\n",
    "forest_predictions = cross_val_predict(forest_model, train_df[features], train_df[label], cv=4)\n",
    "\n",
    "# Evaluate logistic regression model with accuracy score, a confusion matrix, and a classification report\n",
    "print('Random Forest Accuracy Score: %s' %metrics.accuracy_score(train_df[label], forest_predictions))\n",
    "\n",
    "print('Random Forest Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(train_df[label], forest_predictions))\n",
    "\n",
    "print('Random Forest Classification Report:')\n",
    "print(metrics.classification_report(forest_predictions, train_df[label]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
