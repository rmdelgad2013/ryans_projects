{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting and Storing Data from the Web\n",
    "===\n",
    "**Using BeautifulSoup, Pandas, and SQL**\n",
    "\n",
    "*by Ryan Delgado*\n",
    "\n",
    "\n",
    "Data collection is the first step in the data science lifecycle. Ideally, the data is easily-available, properly-formatted, and free of any data quality issues. More often than not, however, this isn't the case. The data we need may be on the web but inaccessible through an API and can contain missing values or incorrect data. This tutorial will show how Python tools can be used to extract and process data from the web, and then warehouse it in a relational database. The purpose is to simulate a a data collection process that facilitates data analysis.  The tutorial is divided into three main sections:\n",
    "1. Introduction to the data and tools\n",
    "2. Basic extraction and processing of data\n",
    "3. Storing data in a relational database\n",
    "\n",
    "The tutorial will conclude with potential future directions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and Tools\n",
    "===\n",
    "\n",
    "We'll work with Short Interest data for US Equities. Short Interest is the quantity of shares that investors are holding short. This figure (and the Short Interest Ratio) are useful for guaging market sentiment. Short Interest data isn't easily available on the web, but it can be bought (e.g. from http://shortsqueeze.com), or it can be found on www.nasdaq.com:\n",
    "\n",
    "<img src='goog_screenshot.png'>\n",
    "\n",
    "We could copy and paste this data into Excel worksheets, but this is very tedious for a large number of stocks, and we'd need to repeat this every 2 weeks to keep up with the data. It's easier to instead automate this with several tools:\n",
    "+ **requests** - A standard Python library for downloading web pages. We'll use this to download the HTML pages into memory for parsing.\n",
    "+ **BeautifulSoup4** - A screen scraping library that we'll use to parse HTML pages\n",
    "+ **Pandas/NumPy** - Standard Python data analysis and manipulation libraries we'll use to process the data.\n",
    "+ **SQLite3** - A Python API to interact with SQLite databases, which are simple and small relational databases. We'll use this library to warehouse the data in a simple relational database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Data Extraction and Processing\n",
    "===\n",
    "\n",
    "We'll start by figuring out the list of stocks we want to gather data on. We'll focus on the 20 most actively traded equities in Nasdaq in this tutorial. A table containing these stocks can be found at http://www.nasdaq.com/markets/most-active.aspx:\n",
    "\n",
    "<img src='most_active.PNG'>\n",
    "\n",
    "We'll download and parse the page, and then extract the table of interest into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "request = requests.get('http://www.nasdaq.com/markets/most-active.aspx')\n",
    "content = request.content\n",
    "mostactive_parser = BeautifulSoup(content, 'html.parser')\n",
    "mostactive_table = str(mostactive_parser.select('#_active > table')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "+ '#_active > table' is a **CSS Selector*** that I found using Chrome Dev Tools. This selector identifies the element of itnerest on a webpage.\n",
    "+ BeautifulSoup's select function returns a list of elements that match the select statement. In this case it returns a single-element list, and we access that element with the [0] index. We also convert it to a string so it can be read by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company</th>\n",
       "      <th>Last Sale*</th>\n",
       "      <th>Change Net / %</th>\n",
       "      <th>Share Volume</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIRI</td>\n",
       "      <td>Sirius XM Holdings Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$ 4.11</td>\n",
       "      <td>unch</td>\n",
       "      <td>75359436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$ 113.72</td>\n",
       "      <td>0.76 ▼ 0.66%</td>\n",
       "      <td>34778615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XIV</td>\n",
       "      <td>VelocityShares Daily Inverse VIX Short Term ETN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$ 37.65</td>\n",
       "      <td>1.70 ▼ 4.32%</td>\n",
       "      <td>34648336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>PowerShares QQQ Trust, Series 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$ 117.10</td>\n",
       "      <td>0.74 ▼ 0.63%</td>\n",
       "      <td>32113033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$ 59.87</td>\n",
       "      <td>0.23 ▼ 0.38%</td>\n",
       "      <td>31551070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                          Company  Last Sale*  \\\n",
       "0   SIRI                          Sirius XM Holdings Inc.         NaN   \n",
       "1   AAPL                                       Apple Inc.         NaN   \n",
       "2    XIV  VelocityShares Daily Inverse VIX Short Term ETN         NaN   \n",
       "3    QQQ                  PowerShares QQQ Trust, Series 1         NaN   \n",
       "4   MSFT                            Microsoft Corporation         NaN   \n",
       "\n",
       "  Change Net / %  Share Volume  Unnamed: 5  \n",
       "0         $ 4.11          unch    75359436  \n",
       "1       $ 113.72  0.76 ▼ 0.66%    34778615  \n",
       "2        $ 37.65  1.70 ▼ 4.32%    34648336  \n",
       "3       $ 117.10  0.74 ▼ 0.63%    32113033  \n",
       "4        $ 59.87  0.23 ▼ 0.38%    31551070  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostactive_table_pd = pd.read_html(mostactive_table)[0]\n",
    "assert mostactive_table_pd.columns.tolist() == ['Symbol', 'Company', 'Last Sale*', 'Change Net / %', 'Share Volume', 'Unnamed: 5']\n",
    "assert len(mostactive_table_pd) == 20\n",
    "\n",
    "mostactive_table_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We have the table of most active stocks in a DataFrame. Let's convert the Symbol column to a list so we can iterate through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIRI', 'AAPL', 'XIV', 'QQQ', 'MSFT', 'FB', 'MU', 'FTR', 'INTC', 'CSCO', 'AMGN', 'QCOM', 'GRPN', 'TVIX', 'CMCSA', 'NXPI', 'ZNGA', 'GILD', 'GT', 'PYPL']\n"
     ]
    }
   ],
   "source": [
    "mostactive_tickers = mostactive_table_pd['Symbol'].tolist()\n",
    "print(mostactive_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to download and process the short interest data for each stock. We'll account for common issues with web scraping, such as:\n",
    "+ Missing data, as denoted by \"-\", \"N/A\" or some other string. We can detect this by checking the dtype of the columns and ensuring the columns we expect to be numeric are indeed numeric (e.g. int64 or float64).\n",
    "+ The table simply not showing up on the page. This would happen if we try to scrape a stock from Nasdaq.com that doesn't trade on Nasdaq.\n",
    "\n",
    "We'll iterate through each stock in the list, and perform these steps:\n",
    "1. Download the web page for the stock, and check that there is indeed short interest data\n",
    "2. Parse the HTML using BeautifulSoup, and extract the short interest data into a DataFrame\n",
    "3. Check the quality of the data - ensure the columns we expect to be in the table are there, and the dtypes are what we expect them to be.\n",
    "4. If the checks pass, append the DataFrame to our list of DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Nasdaq short interest data for SIRI\n",
      "Quality checks passed for SIRI. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for AAPL\n",
      "Quality checks passed for AAPL. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for XIV\n",
      "Quality checks passed for XIV. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for QQQ\n",
      "Quality checks passed for QQQ. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for MSFT\n",
      "Quality checks passed for MSFT. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for FB\n",
      "Quality checks passed for FB. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for MU\n",
      "Quality checks passed for MU. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for FTR\n",
      "Quality checks passed for FTR. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for INTC\n",
      "Quality checks passed for INTC. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for CSCO\n",
      "Quality checks passed for CSCO. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for AMGN\n",
      "Quality checks passed for AMGN. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for QCOM\n",
      "Quality checks passed for QCOM. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for GRPN\n",
      "Quality checks passed for GRPN. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for TVIX\n",
      "Quality checks passed for TVIX. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for CMCSA\n",
      "Quality checks passed for CMCSA. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for NXPI\n",
      "Quality checks passed for NXPI. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for ZNGA\n",
      "Quality checks passed for ZNGA. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for GILD\n",
      "Quality checks passed for GILD. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for GT\n",
      "Quality checks passed for GT. Appending to Nasdaq frames list\n",
      "Scraping Nasdaq short interest data for PYPL\n",
      "Quality checks passed for PYPL. Appending to Nasdaq frames list\n",
      "Short Interest data scraped successfully for 20 out of 20 stocks\n"
     ]
    }
   ],
   "source": [
    "nasdaq_frames = []\n",
    "    \n",
    "for ticker in mostactive_tickers:\n",
    "    \n",
    "    # Download HTML page for ticker's short interest\n",
    "    print('Scraping Nasdaq short interest data for {}'.format(ticker))\n",
    "    req = requests.get('http://www.nasdaq.com/symbol/{}/short-interest'.format(ticker))\n",
    "    content = str(req.content)\n",
    "\n",
    "    # Stocks that don't have short interest data on Nasdaq will show a page that says \n",
    "    # \"This page does not support NYSE and AMEX Short Interest.\" We can search for this string in the page to use as an \n",
    "    # indicator that there isn't short interest data for this stock. If we find this string in the page, we'll skip this\n",
    "    # iteration and move on to the next ticker.\n",
    "    if 'This page does not support' in content:\n",
    "        print('Short Interest data is not available for {}'.format(ticker))\n",
    "        continue\n",
    "\n",
    "    # Parse the HTML page, then capture the Short Interest table using its CSS Selector (found using Chrome dev tools)\n",
    "    nasdaq_parser = BeautifulSoup(content, 'html.parser')    \n",
    "    nasdaq_table = str(nasdaq_parser.select('#quotes_content_left_ShortInterest1_ShortInterestGrid')[0])\n",
    "    nasdaq_frame = pd.read_html(nasdaq_table)[0]\n",
    "\n",
    "    # Quality checks. We know previously that there are always four columns. Check that the four column names \n",
    "    # match what we expect and that the data types of the columns match what we expect. If the\n",
    "    # checks do not pass, print a message then skip to the next iteration.\n",
    "    try:\n",
    "        assert nasdaq_frame.columns.tolist() == ['Settlement Date', 'Short Interest', 'Avg Daily Share Volume', 'Days To Cover']\n",
    "        assert nasdaq_frame.dtypes.tolist() == [np.dtype('O'), np.dtype('int64'), np.dtype('int64'), np.dtype('float64')]        \n",
    "    except AssertionError:\n",
    "        print('Quaity checks failed for {}. This data will not be appended to Nasdaq frames list.'.format(ticker))\n",
    "        continue\n",
    "\n",
    "    # If the quality checks pass, add a column for the symbol and append to the nasdaq_frames list.\n",
    "    print('Quality checks passed for {}. Appending to Nasdaq frames list'.format(ticker))\n",
    "    nasdaq_frame['symbol'] = ticker\n",
    "    nasdaq_frames.append(nasdaq_frame)\n",
    "\n",
    "# Summary report\n",
    "total_successes = len(nasdaq_frames)\n",
    "total_tickers = len(mostactive_tickers)\n",
    "print('Short Interest data scraped successfully for {} out of {} stocks'.format(total_successes, total_tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the frame for Sirius XM as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Settlement Date</th>\n",
       "      <th>Short Interest</th>\n",
       "      <th>Avg Daily Share Volume</th>\n",
       "      <th>Days To Cover</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/14/2016</td>\n",
       "      <td>207206065</td>\n",
       "      <td>40275240</td>\n",
       "      <td>5.144751</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/30/2016</td>\n",
       "      <td>220922513</td>\n",
       "      <td>44733332</td>\n",
       "      <td>4.938655</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/15/2016</td>\n",
       "      <td>229413860</td>\n",
       "      <td>55949317</td>\n",
       "      <td>4.100387</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/31/2016</td>\n",
       "      <td>221459290</td>\n",
       "      <td>53000940</td>\n",
       "      <td>4.178403</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/15/2016</td>\n",
       "      <td>221124840</td>\n",
       "      <td>51604416</td>\n",
       "      <td>4.284998</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Settlement Date  Short Interest  Avg Daily Share Volume  Days To Cover  \\\n",
       "0      10/14/2016       207206065                40275240       5.144751   \n",
       "1       9/30/2016       220922513                44733332       4.938655   \n",
       "2       9/15/2016       229413860                55949317       4.100387   \n",
       "3       8/31/2016       221459290                53000940       4.178403   \n",
       "4       8/15/2016       221124840                51604416       4.284998   \n",
       "\n",
       "  symbol  \n",
       "0   SIRI  \n",
       "1   SIRI  \n",
       "2   SIRI  \n",
       "3   SIRI  \n",
       "4   SIRI  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siri_frame = nasdaq_frames[0]\n",
    "siri_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the Data in a Relational Database\n",
    "===\n",
    "\n",
    "We're ready to store the data. We can easily store these tables as separate CSV files in a local file system, but a more elegant and space-efficient solution is to store the data in a relational database. Let's create a basic SQLite database with 5 tables:\n",
    "+ A *Company* dimension table, containing the symbol and full company name of each stock\n",
    "+ A *Measure* dimension table, containing the measure names (Short Interest, Days To Cover, etc.)\n",
    "+ A *Date* dimension table, containing the dates each value could take\n",
    "+ An *Equity_historical* fact table, containing foreign keys for the dimensions and the actual values for the data we extract\n",
    "+ An *Equity_stage* table that's an intermediate staging table for adding the data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x295f17c4c70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create Equities_mart database\n",
    "conn = sqlite3.connect('equities_mart.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create Company, Measure, and Date dimension tables\n",
    "cursor.execute('''\n",
    "CREATE TABLE Company(\n",
    "    id     integer PRIMARY KEY,\n",
    "    symbol text,\n",
    "    name   text\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE Measure(\n",
    "    id           integer PRIMARY KEY,\n",
    "    measure_name text\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE Date(\n",
    "    id   integer PRIMARY KEY,\n",
    "    date text\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Create Equity_historical fact table\n",
    "cursor.execute('''\n",
    "CREATE TABLE Equity_historical(\n",
    "    id         integer PRIMARY KEY,\n",
    "    company_id integer,    \n",
    "    date_id    integer,\n",
    "    measure_id integer,\n",
    "    value      real,\n",
    "    FOREIGN KEY(company_id) REFERENCES Company(id),\n",
    "    FOREIGN KEY(measure_id) REFERENCES Measure(id),\n",
    "    FOREIGN KEY(date_id) REFERENCES Date(id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Create Equity_stage table\n",
    "cursor.execute('''\n",
    "CREATE TABLE Equity_stage(\n",
    "    id      integer PRIMARY KEY,\n",
    "    date    text,    \n",
    "    symbol  text,\n",
    "    measure text,\n",
    "    value   real\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's populate the dimension tables based on the data we scraped from Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_frame = mostactive_table_pd[['Symbol','Company']]\n",
    "company_frame.columns = ['symbol','name']\n",
    "company_frame.to_sql(name='Company', con=conn, if_exists='append', index=False)\n",
    "\n",
    "measure_frame = pd.DataFrame(['Short Interest', 'Avg Daily Share Volume', 'Days To Cover'])\n",
    "measure_frame.columns = ['measure_name']\n",
    "measure_frame.to_sql(name='Measure', con=conn, if_exists='append', index=False)\n",
    "\n",
    "date_frame = pd.DataFrame(siri_frame['Settlement Date'])\n",
    "date_frame.columns = ['date']\n",
    "date_frame.to_sql(name='Date', con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The short interest frames are \"wide\" tables, in that the measures are individual columns. This is ideal for data analysis, but doesn't quite fit with the database schema. We'll define a function that \"elongates\" the frame (using the pandas melt function), which we can then write to the stage table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_stage_frame(raw_frame):\n",
    "\n",
    "    # Change the dtypes of the ShortInterest and ShareVolume columns to float64 so there aren't any conflicts when melting\n",
    "    # the frame.\n",
    "    raw_frame['Short Interest'] = raw_frame['Short Interest'].astype(np.dtype('float64'))\n",
    "    raw_frame['Avg Daily Share Volume'] = raw_frame['Avg Daily Share Volume'].astype(np.dtype('float64'))\n",
    "    \n",
    "    # Melt raw_frame so that the measure columns are stacked into one column, and the measure names are placed in \n",
    "    # another column. Keep the Date and Symbol columns the same.\n",
    "    melted_frame = pd.melt(raw_frame, id_vars=['Settlement Date', 'symbol'], \n",
    "                           value_vars=['Short Interest','Avg Daily Share Volume','Days To Cover'])\n",
    "    \n",
    "    # Rename columns to fit in the staging table\n",
    "    melted_frame.columns = ['date','symbol','measure','value']\n",
    "    \n",
    "    return melted_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's collect the short interest data again, but we'll append the data to the Equity_stage table instead of a list of DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Nasdaq short interest data for SIRI\n",
      "Quality checks passed for SIRI. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for AAPL\n",
      "Quality checks passed for AAPL. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for XIV\n",
      "Quality checks passed for XIV. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for QQQ\n",
      "Quality checks passed for QQQ. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for MSFT\n",
      "Quality checks passed for MSFT. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for FB\n",
      "Quality checks passed for FB. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for MU\n",
      "Quality checks passed for MU. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for FTR\n",
      "Quality checks passed for FTR. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for INTC\n",
      "Quality checks passed for INTC. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for CSCO\n",
      "Quality checks passed for CSCO. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for AMGN\n",
      "Quality checks passed for AMGN. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for QCOM\n",
      "Quality checks passed for QCOM. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for GRPN\n",
      "Quality checks passed for GRPN. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for TVIX\n",
      "Quality checks passed for TVIX. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for CMCSA\n",
      "Quality checks passed for CMCSA. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for NXPI\n",
      "Quality checks passed for NXPI. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for ZNGA\n",
      "Quality checks passed for ZNGA. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for GILD\n",
      "Quality checks passed for GILD. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for GT\n",
      "Quality checks passed for GT. Appending to Equity_stage\n",
      "Scraping Nasdaq short interest data for PYPL\n",
      "Quality checks passed for PYPL. Appending to Equity_stage\n"
     ]
    }
   ],
   "source": [
    "for ticker in mostactive_tickers:\n",
    "    \n",
    "    # Download HTML page for ticker's short interest\n",
    "    print('Scraping Nasdaq short interest data for {}'.format(ticker))\n",
    "    req = requests.get('http://www.nasdaq.com/symbol/{}/short-interest'.format(ticker))\n",
    "    content = str(req.content)\n",
    "\n",
    "    # Stocks that don't have short interest data on Nasdaq will show a page that says \n",
    "    # \"This page does not support NYSE and AMEX Short Interest.\" We can search for this string in the page to use as an \n",
    "    # indicator that there isn't short interest data for this stock. If we find this string in the page, we'll skip this\n",
    "    # iteration and move on to the next ticker.\n",
    "    if 'This page does not support' in content:\n",
    "        print('Short Interest data is not available for {}'.format(ticker))\n",
    "        continue\n",
    "\n",
    "    # Parse the HTML page, then capture the Short Interest table using its CSS Selector (found using Chrome dev tools)\n",
    "    nasdaq_parser = BeautifulSoup(content, 'html.parser')    \n",
    "    nasdaq_table = str(nasdaq_parser.select('#quotes_content_left_ShortInterest1_ShortInterestGrid')[0])\n",
    "    nasdaq_frame = pd.read_html(nasdaq_table)[0]\n",
    "\n",
    "    # Quality checks. We know previously that there are always four columns and 25 rows. Check that the four column names \n",
    "    # match what we expect, that the data types of the columns match what we expect, and that there are 25 rows. If the\n",
    "    # checks do not pass, print a message then\n",
    "    try:\n",
    "        assert nasdaq_frame.columns.tolist() == ['Settlement Date', 'Short Interest', 'Avg Daily Share Volume', 'Days To Cover']\n",
    "        assert nasdaq_frame.dtypes.tolist() == [np.dtype('O'), np.dtype('int64'), np.dtype('int64'), np.dtype('float64')]        \n",
    "        assert len(nasdaq_frame) == 25\n",
    "    except AssertionError:\n",
    "        print('Quaity checks failed for {}. This data will not be appended to Nasdaq frames list.'.format(ticker))\n",
    "        continue\n",
    "\n",
    "    # If the quality checks pass, add a column for the symbol and append to the nasdaq_frames list.  \n",
    "    # Transform the nasdaq_frame into a DataFrame that can fit in the stage table, then append to Equity_stage.\n",
    "    print('Quality checks passed for {}. Appending to Equity_stage'.format(ticker))\n",
    "    nasdaq_frame['symbol'] = ticker\n",
    "    prepped_stage_frame = prep_stage_frame(nasdaq_frame)\n",
    "    prepped_stage_frame.to_sql(name='Equity_stage', con=conn, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll normalize the data in the Equity_stage table based on the dimension tables, and insert this normalized table into the Equity_historical table. We'll empty the Equity_stage table after the data has been successfully transferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x295f17c4c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set stage table to the fact table\n",
    "cursor.execute('''\n",
    "INSERT INTO Equity_historical (company_id, date_id, measure_id, value)\n",
    "SELECT c.id as company_id, d.id as date_id, m.id as measure_id, value\n",
    "    FROM Equity_stage e\n",
    "    JOIN Company c\n",
    "        ON e.symbol = c.symbol\n",
    "    JOIN Date d\n",
    "        ON e.date = d.date\n",
    "    JOIN Measure m\n",
    "        ON e.measure = m.measure_name\n",
    "    ;\n",
    "'''\n",
    ")\n",
    "\n",
    "# Clear contents of the stage table \n",
    "cursor.execute('''\n",
    "DELETE FROM Equity_stage;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick query on the Equity_historical table to make sure the data looks as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>measure_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>207206065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>220922513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>229413860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>221459290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>221124840.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  company_id  date_id  measure_id        value\n",
       "0   1           1        1           1  207206065.0\n",
       "1   2           1        2           1  220922513.0\n",
       "2   3           1        3           1  229413860.0\n",
       "3   4           1        4           1  221459290.0\n",
       "4   5           1        5           1  221124840.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT * FROM Equity_historical;\n",
    "'''\n",
    "\n",
    "historical_frame = pd.read_sql(sql=query, con=conn)\n",
    "historical_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. We can now query the database to retrieve data we want. As an example, let's query Date & Short Interest data for AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Short_Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/14/2016</td>\n",
       "      <td>56005114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/30/2016</td>\n",
       "      <td>54716610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/15/2016</td>\n",
       "      <td>60135782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/31/2016</td>\n",
       "      <td>47083129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/15/2016</td>\n",
       "      <td>51758571.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Short_Interest\n",
       "0  10/14/2016      56005114.0\n",
       "1   9/30/2016      54716610.0\n",
       "2   9/15/2016      60135782.0\n",
       "3   8/31/2016      47083129.0\n",
       "4   8/15/2016      51758571.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT d.date as Date, e.value as Short_Interest\n",
    "    FROM Equity_historical e\n",
    "    JOIN Date d\n",
    "        ON e.date_id = d.id\n",
    "    JOIN Company c\n",
    "        ON e.company_id = c.id\n",
    "    JOIN Measure m\n",
    "        ON e.measure_id = m.id\n",
    "    WHERE c.symbol       = \"AAPL\"\n",
    "    AND   m.measure_name = \"Short Interest\"\n",
    "    ;\n",
    "'''\n",
    "\n",
    "aapl_shortinterest_historical = pd.read_sql(query, conn)\n",
    "aapl_shortinterest_historical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! We've successfully extracted the data from Nasdaq.com and efficiently stored it in a relational database. The data is ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "===\n",
    "\n",
    "This tutorial showed an example ETL workflow for collecting and storing data from the web using BeautifulSoup, pandas, and SQLite. This is only an example workflow that could be used for small, individual projects. We could improve this by\n",
    "+ Using a more scalable RDBMS like MySQL or Oracle instead of SQLite, perhaps in a cloud-based solution like Amazon Redshift.\n",
    "+ Using Scrapy instead of requests/BeautifulSoup. Scrapy is a web scraping framework rather than just a parsing library like BeautifulSoup or LXML, and it has more capabilities.\n",
    "+ Expanding our stock universe to all stocks that trade on Nasdaq.\n",
    "+ Adding more quality checks and robust handling of issues - what if requests no longer works? What if the Most Active Stocks page disappears?\n",
    "+ Turning this code into Python scripts, placing them in an Amazon EC2 server, and automating this collection process with cron.\n",
    "\n",
    "I hope this tutorial was useful to you. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
